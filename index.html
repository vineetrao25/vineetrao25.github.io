<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kemmannu Vineet Venkatesh Rao</title>
  
  <meta name="author" content="Kemmannu Vineet Venkatesh Rao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="shortcut icon" href="https://umich.edu/favicon.ico"/>
  
<script type="text/javascript">
window.onload = function() {
  var image = document.getElementById("img");
  var num=1
  var total=5; 
  var imageWidth = 225; 
  var imageHeight = 300; 

  function updateImage() {
      num =num+1 
      if (num >total) {num=1} 
      image.src = "images/website_images/website_image"+ num +".jpg";
      
      image.style.width = imageWidth + "px";
      image.style.height = imageHeight + "px";
  }
  setInterval(updateImage, 5000);
}
</script>

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> K Vineet Venkatesh Rao</name>
              </p>
              <p> 
                Hi! I am an Master's graduate in Electrical Engineering and Computer Science from University of Michigan Ann Arbor, where I specialized in Signal, Image Processing, and Machine Learning. I am passionate about leveraging cutting-edge technology to create a meaningful and positive impact on the world.
              </p>
              <p>
                I obtained my undergraduate degree in Electronics and Communication Engineering, complemented by a minor in Computer Science, from PES University in 2020. My educational background, combined with my courses at the University of Michigan, have helped me develop a strong foundation in computer vision and machine learning.  
              </p>
              <p>
                If you have a similar passion for technology and innovation, I'd love to connect with you. Whether we explore potential research collaborations or simply engage in insightful conversations about the latest advancements in our field, feel free to get in touch with me. 
              </p>
              <p>
                Feel free to say hi at : <b><i>kemmannu<i> at umich dot edu</b>
              </p>
              <p style="text-align:center">
                <a href="data/Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://twitter.com/vineetrao25">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/vineetrao25/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:40%">
              <a href="images/website_images/website_image1.jpg"><img style="width:100% ;max-width:800px" alt="profile photo" src="images/website_images/website_image1.jpg" class="hoverZoomLink" id="img"> </a>
            </td>
            
          </tr> 
          <!-- Miniature logos row -->
          <tr style="padding:0px">
            <td colspan="1" style="text-align: center;">
              <img style="width: 30%; max-width: 130px; margin: 5px;" alt="Amazon Intern Logo" src="images/logos/amazon_intern_logo.png">
              <img style="width: 30%; max-width: 130px; margin: 5px;" width="300" alt="Amazon Lab126 Logo" src="images/logos/amazon_lab126_logo.png">
              <img style="width: 30%; max-width: 100px; margin: 5px;" alt="Umich Logo" src="images/logos/um_logo.png">
              <img style="width: 30%; max-width: 130px; margin: 5px;" alt="PES University Logo" src="images/logos/pesu_logo.png">
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                 I'm broadly interested in intersection Computer Vision, Deep Learning and NLP.  I am particularly interested in exploring self-supervised representational learning methods, utilizing multi-modal pretraining, especially language supervised pretraining, to address challenging vision tasks such as classification and detection. 
              </p> 
              <papertitle> Research Associate — Prof. Justin Johnson's AI Lab  &nbsp; (JAIL) </papertitle> 

                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Aug. 2022 - Apr 2023  
              <p>
                Developing a novel training recipe for open vocabulary instance segmentation without the need for aligned data, inspired by the distinct ”what” and ”where” pathways observed in the human visual system (working towards
                submission for <b>ICLR 2024</b>)
              </p>
            </td>
          </tr>
        </tbody></table>  

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Experience</heading>
            <br>
            <br>
            <papertitle>Applied Scientist Intern at Amazon Lab 126 </papertitle>  
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   May 2022 - Aug 2022
              <br>
              <em>Sunnyvale, CA </em>, Manager:<a href="https://www.linkedin.com/in/prasadshamain/">Prasad Shamain</a>               
              <br>
              <p>
                Conducted research, collaboration, and implementation of a privacy-focused Deep Learning solution for a complex problem involving radar inputs for a specific Amazon product
              </p>  
              <p>
                Designed and implemented a Computer Vision Ground Truth system, Data-Collection pipeline, and synchronization, while exploring different deep learning methods for a Radar Based System, considering resource constraints and providing key insights for decision-making
              </p>

          </td> 
          </tr>
        </tbody></table> 

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Projects</heading>
            <p>
               Here are some of the projects that I have been working on :-)
            </p>
          </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/project_images/ml_project.png" alt="SSL Object Detector" width="200" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Self-Supervised Object Detection with Multimodal Image Captioning</papertitle>
              <br>
              <em>EECS 545 Course Project </em>, Supervisor :<a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a>
              <br>
              <a href="data/EECS545Report_Resume.pdf">Report</a>
              /
              <a href="data/Blue_background_horizontal.pptx.pdf">Poster</a>
              <br>
              <p>Our novel proposed method drastically reduces the need of human supervision required for training an Object Detector.</p> 
              <P>Leveraged a language supervised pre-trained bi-directional captioning model (VirTex-v2) that outputs set of diverse captions given an image. </P>
              <p>Further, zero-shot transfered using prompt engineering and then filtered using noun and target extraction modules to get a set of "words of interest" from the generated captions.</p>
              <p>Using these "words of interest", utilized Gradient Class Activation Maps to localize an object given an image and draw a bounding box around it. Thus, creating a pseudo label and pseudo bounding boxes that act as supervision to train the Object Detector.</p>
              <p>Finally, trained a Fully Convolution Single Stage Object Detector (FCOS) using new small modified verison of GioU loss to account for the noise in the generated pseudo bounding boxes. We verify our techniques on Pascal-VOC dataset. </p>
            </td>
          </tr>
        </tbody></table>

        <br>
        <br>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/project_images/dlcv_project.png" alt="Fine-grained Food Classification" width="200" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Language Supervised Vision Pre-Training for Fine-grained Food Classification </papertitle>
              
              <br>
              <em>EECS 598 Course Mini-Project </em>, Supervisor :<a href="https://web.eecs.umich.edu/~justincj/">Justin Johnson</a>
              <br>
              <a href="data/EECS598Report_Website.pdf">Report</a>
              <br>
              <p>Subsampled RedCaps dataset from sub-reddits pertinent to food. Our dataset is unique and contains image-caption pairs from manually curated food related sub-reddits from 04/2020 - 04/2022.</p>
              <p>Pre-trained a bi-directional image captioning model using RegNeX-800MF as feature extractor for image and 2 encoder-decoder transformer layer to learn semantic representations from the captions using our subsampled dataset.</p> 
              <P>With limited hardware resources, our best model acheived 20 % zero shot accuracy on the test-set of Food-101 dataset. </P>
            </td>
          </tr>
        </tbody></table>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/project_images/ml_vlsi.png" alt="Fine-grained Food Classification" width="200" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Quantized Winograd Convolution based accerlator for Convolutional Neural Networks  </papertitle>
              <br>
              <em>EECS 598 Course Project </em>, Supervisor :<a href="https://kim.engin.umich.edu/">Hun-Seok Kim</a>
              <br>
              <a href="data/EECS598001Repost_Website.pdf">Report</a>
              <br>
              <p>Developed a 8-bit Quantized Flexible Winograd based Convolutional Engine in verilog for decreased inference time and model size. Simulated the entire inference cycle of a CNN in MATLAB</p> 
              <P>Investigated and implemented various Quantization techniques used in tinyML to reduce the model complexity.</P>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>



<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr style="padding:0px">
    <td style="padding:0px">

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody>
      </table>
      
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/logos/um_logo.png" alt="cs188" width="128">
          </td>
          <td width="75%" valign="center">
            Graduate Student Instructor 
            <br>
            <br>
            <a href="https://ece.engin.umich.edu/academics/course-information/course-descriptions/eecs-452/">EECS 452:  Digital Signal Processing Laboratory</a> (Fall 2022), <a href="https://www.birds.eecs.umich.edu/"> Prof. Shai Revzen </a>
            <br>
            <br>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/logos/um_logo.png" alt="cs188" width="128">
          </td>
          <td width="75%" valign="center">
            Graduate Student Instructor 
            <br>
            <br>
            <a href="https://ece.engin.umich.edu/academics/course-information/course-descriptions/eecs-452/">EECS 452:  Digital Signal Processing Laboratory</a> (Winter 2023), <a href="https://arsarabi.github.io/"> Prof. Armin Sarabi </a>
            <br>
            <br>
          </td>
        </tr>
      </tbody></table>
    </td> 
  </tr> 
</table>  

  Website style borrowed from  <a href="https://jonbarron.info/">here</a>.
</body> 
</html>
