<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kemmannu Vineet Venkatesh Rao</title>
  
  <meta name="author" content="Kemmannu Vineet Venkatesh Rao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="shortcut icon" href="https://umich.edu/favicon.ico"/>
  
  <!----
  <script type="text/javascript">
    var current = 1; 
    var total = 3; 
    var time; 
    function imageChanger() { time=setTimeout(imageChanger(), 1000); 
    current =current+1;
    if(current > total) current=1;
    document.getElementById("image").src="images/website_image"+current+".jpg";
     }  
  </script>
--> 
<script type="text/javascript">
window.onload = function() {
  var image = document.getElementById("img");

  function updateImage() {
      var min=1; 
      var max=3; 
      const random = (min, max) => Math.floor(Math.random() * (max - min)) + min;
      image.src = "images/website_image"+random+".jpg";
  }
  setInterval(updateImage, 1000);
}
</script>

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Vineet Rao</name>
              </p>
              <p> 
                I am a second year EECS MSc student at the University of Michigan, majoring in Signal, Image Processing and Machine learning. My courses and career aspirations are both aligned in Computer Vision and Machine Learning. 
              </p>
              <p>
                Prior to joining UMich, I graduated from PES University in 2020, with a major in Electronics and Communication Engineering and a minor in Computer Science.  
              </p>
              <p>
                Please feel free to contact me if you want to talk about potential research colloboration or just want to chat :)
              </p>
              <p style="text-align:center">
                <a href="mailto:kemmannu@umich.edu">Email</a> &nbsp/&nbsp
                <a href="data/Resume-F22.pdf">CV</a> &nbsp/&nbsp
                <a href="https://twitter.com/vineetrao25">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/vineetrao25/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:40%">
              <a href="images/website_image1.jpg"><img style="width:80%;max-width:100%" alt="profile photo" src="images/website_image1.jpg" class="hoverZoomLink" id="img"> </a>
              <a href="images/amazon_intern.png"><img style="width:80%;max-width:100%" alt="profile photo" src="images/amazon_intern.png" class="hoverZoomLink"></a>
            </td>
            
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                 I'm broadly interested in Computer Vision, Machine Learning, Deep Learning and NLP. My current research interests are in Self-Supervised representational learning, leveraging multi-modal pretraining (particularly language supervised pretraining) to solve down-stream vision tasks of classification and detection.
              </p>
            </td>
          </tr>
        </tbody></table>  

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Experience</heading>
            <br>
            <br>
            <span class="highlight">
              <papertitle>Applied Scientist Intern at Amazon Lab 126 </span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   May 2022 - Aug 2022
              </papertitle>  
            
              <br>
              <em>Sunnyvale, CA </em>, Manager:<a href="https://www.linkedin.com/in/prasadshamain/">Prasad Shamain</a>               <br>
              <p>Researched, colloborated and implemented a privacy centric Deep Learning based solution for a complex problem involving radar inputs that intersected with a particular Amazon V0 product (cannot disclose due to confidentiality).</p> 
              <P>Designed and implemented a Computer Vision based Ground Truth system, Data-Collection pipeline and synchronization, and also investiaged various deep learning methods for the Radar Based System and came up with the data-points in deciding which one to use given the resource constraints. </P>
              <p>Presented the project to the team director and it receievd a green-light to be continued as a NTI. </p>
              <p>Also learned peculiar "Amazon Leadership Principles", interacted with several managers and scientists outside my team to learn on how to come up with a suitable metrics through literature survey given a vague problem statement.</p>
              <p>Most importantly, I was able to learn pitfalls that might occur in designing a consumer based product and the steps taken to mitigate them through interaction with my skip-managers and team members. </p>
          </td>
          </tr>
        </tbody></table> 

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Projects</heading>
            <p>
               Here are some of the projects that I have been working on :-)
            </p>
          </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SSL-BlockDiagram.png" alt="SSL Object Detector" width="200" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Self-Supervised Object Detection with Multimodal Image Captioning</papertitle>
              <br>
              <em>EECS 545 Course Project </em>, Supervisor :<a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a>
              <br>
              <a href="data/EECS545Report_Resume.pdf">Report</a>
              /
              <a href="data/Blue_background_horizontal.pptx.pdf">Poster</a>
              <br>
              <p>Our novel proposed method drastically reduces the need of human supervision required for training an Object Detector.</p> 
              <P>Leveraged a language supervised pre-trained bi-directional captioning model (VirTex-v2) that outputs set of diverse captions given an image. </P>
              <p>Further, zero-shot transfered using prompt engineering and then filtered using noun and target extraction modules to get a set of "words of interest" from the generated captions.</p>
              <p>Using these "words of interest", utilized Gradient Class Activation Maps to localize an object given an image and draw a bounding box around it. Thus, creating a pseudo label and pseudo bounding boxes that act as supervision to train the Object Detector.</p>
              <p>Finally, trained a Fully Convolution Single Stage Object Detector (FCOS) using new small modified verison of GioU loss to account for the noise in the generated pseudo bounding boxes. We verify our techniques on Pascal-VOC dataset. </p>
            </td>
          </tr>
        </tbody></table>

        <br>
        <br>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/Inference_cap2.png" alt="Fine-grained Food Classification" width="200" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Language Supervised Vision Pre-Training for Fine-grained Food Classification </papertitle>
              
              <br>
              <em>EECS 598 Course Mini-Project </em>, Supervisor :<a href="https://web.eecs.umich.edu/~justincj/">Justin Johnson</a>
              <br>
              <a href="data/EECS598Report_Website.pdf">Report</a>
              <br>
              <p>Subsampled RedCaps dataset from sub-reddits pertinent to food. Our dataset is unique and contains image-caption pairs from manually curated food related sub-reddits from 04/2020 - 04/2022.</p>
              <p>Pre-trained a bi-directional image captioning model using RegNeX-800MF as feature extractor for image and 2 encoder-decoder transformer layer to learn semantic representations from the captions using our subsampled dataset.</p> 
              <P>With limited hardware resources, our best model acheived 20 % zero shot accuracy on the test-set of Food-101 dataset. </P>
            </td>
          </tr>
        </tbody></table>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/Winograd.png" alt="Fine-grained Food Classification" width="200" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Quantized Winograd Convolution based accerlator for Convolutional Neural Networks  </papertitle>
              <br>
              <em>EECS 598 Course Project </em>, Supervisor :<a href="https://kim.engin.umich.edu/">Hun-Seok Kim</a>
              <br>
              <a href="data/EECS598001Repost_Website.pdf">Report</a>
              <br>
              <p>Developed a 8-bit Quantized Flexible Winograd based Convolutional Engine in verilog for decreased inference time and model size. Simulated the entire inference cycle of a CNN in MATLAB</p> 
              <P>Investigated and implemented various Quantization techniques used in tinyML to reduce the model complexity.</P>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
  Website style borrowed from  <a href="https://jonbarron.info/">here</a>.
</body> 
</html>
